{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "606f2a84",
   "metadata": {},
   "source": [
    "# Gaussian Processes\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChemAI-Lab/AI4Chem/blob/main/website/modules/02-gaussian_processes.ipynb) \n",
    "\n",
    "**References:**\n",
    "1. **Chapter 2**:  [Gaussian Processes for Machine LearningOpen Access](https://direct.mit.edu/books/oa-monograph-pdf/2514321/book_9780262256834.pdf), C. E. Rasmussen, C. K. I. Williams\n",
    "2. **Chapters 6**: [Pattern Recognition and Machine Learning](https://www.microsoft.com/en-us/research/wp-content/uploads/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf), C. M. Bishop.\n",
    "3. **Chapter 4**: [Machine Learning in Quantum Sciences](https://arxiv.org/pdf/2204.04198)\n",
    "4. [**The Kernel Cookbook**](https://www.cs.toronto.edu/~duvenaud/cookbook/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a61d26a",
   "metadata": {},
   "source": [
    "Previously we covered **Kernel methods** and **probabilistic linear models**. \n",
    "Gaussian Processes, is the merge of these two classes of models where we describe probabilistically the family of functions through the kernel function. \n",
    "\n",
    "\n",
    "We saw that the posterior distribution for a linear model is, \n",
    "$$\n",
    "p(\\mathbf{w}|\\mathbf{X}, \\mathbf{y}) \\propto \\exp \\left (-\\frac{1}{2\\sigma_n ^2} \\left (\\mathbf{y} - \\mathbf{X}\\mathbf{w} \\right )^\\top  \\left (\\mathbf{y} - \\mathbf{X}\\mathbf{w} \\right )\\right ) \\exp \\left (-\\frac{\\alpha}{2}\\mathbf{w}^\\top\\mathbf{w} \\right )\n",
    "$$\n",
    "$$\n",
    "p(\\mathbf{w}|\\mathbf{X}, \\mathbf{y}) \\sim {\\cal N} \\left ( \\hat{\\mathbf{w}} = \\frac{1}{\\sigma_n^2} \\mathbf{A}^{-1}\\mathbf{X}^\\top\\mathbf{y}, \\mathbf{A}^{-1} \\right ),\n",
    "$$\n",
    "where $\\mathbf{A} = \\sigma_n^2\\mathbf{X}^\\top \\mathbf{X} + \\frac{1}{\\alpha}I$. <br>\n",
    "* This are exactly the same equations as in the Ridge regression before we apply the **kernel trick**. \n",
    "\n",
    "\n",
    "\n",
    "1. **Prediction Distribution**:\n",
    "   The predicted outputs for new input data points are assumed to follow a normal distribution, denoted as $ y_* $.\n",
    "   $$ y_* \\sim \\ N (\\mu(X_*), \\sigma(X_*)) $$\n",
    "\n",
    "2. **Mean Function $\\mu(X_*)$**:\n",
    "   This function represents the expected value of the predictions for the new input points.\n",
    "   $$ \\mu(X_*) = k(X_*, X)^T [K(X, X) + \\sigma_n^2I]^{-1}y $$\n",
    "\n",
    "3. **Covariance Function $\\sigma(X_*)$**:\n",
    "   This function denotes the uncertainty or variance in the predictions for the new input points.\n",
    "   $$ \\sigma(X_*) = k(X_*, X_*) - k(X_*, X)^T [K(X, X) + \\sigma_n^2I]^{-1}k(X_*, X) $$\n",
    "\n",
    "- Here, $k(X_*, X)$ is the kernel function evaluated between the new input points $X_*$ and the training input points $X$, capturing the covariance between them.\n",
    "- $K(X, X)$ is the kernel matrix evaluated on the training input points, representing the covariance among the training points themselves.\n",
    "- $\\sigma_n^2$ is the variance of the noise in the data, and $I$ is the identity matrix.\n",
    "- $y$ is the vector of observed target values from the training set.\n",
    "\n",
    "The GP model thus provides a distribution over possible functions that fit the observed data, and we use this distribution to make predictions with associated uncertainties.\n",
    "\n",
    "\n",
    "### **Marginal Likelihood**\n",
    "Contrary to Kernel Ridge regression where, cross-validation is required to fit the kernel, \n",
    "The **marginal likelihood** is given by the equation:\n",
    "\n",
    "$$\n",
    "\\log p(\\mathbf{y}|\\mathbf{X}) = -\\frac{1}{2} \\mathbf{y}^T (K + \\sigma_n^2 I)^{-1} \\mathbf{y} - \\frac{1}{2} \\log |K + \\sigma_n^2 I| - \\frac{N}{2} \\log(2\\pi)\n",
    "$$\n",
    "\n",
    "- It represents the probability of generating the observed sample from a prior and is therefore often referred to as **model evidence** or simply evidence.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ac8ba8",
   "metadata": {},
   "source": [
    "## Combination of Kernels\n",
    "\n",
    "Beyond the list of kernels that I have presented, [**The Kernel Cookbook**](https://www.cs.toronto.edu/~duvenaud/cookbook/), it is possible to construct new **valid** kernels using some base ones, \n",
    "1. Sum of kernels: $k_1(\\mathbf{x}_i, \\mathbf{x}_j) + k_2(\\mathbf{x}_i, \\mathbf{x}_j) $\n",
    "2. Product of kernels: $k_1(\\mathbf{x}_i, \\mathbf{x}_j) * k_2(\\mathbf{x}_i, \\mathbf{x}_j) $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21373a2c",
   "metadata": {},
   "source": [
    "We will use the  Mauna Loa Observatory dataset to showcase the power of combining kernels to strength the learning capacity of GPs. [Scikit-learn Tutorial](https://scikit-learn.org/stable/auto_examples/gaussian_process/plot_gpr_co2.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be13a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "import datetime\n",
    "\n",
    "co2 = fetch_openml(data_id=41187, as_frame=True)\n",
    "co2.frame.head()\n",
    "\n",
    "co2_data = co2.frame[[\"year\", \"month\", \"day\", \"co2\"]].copy()\n",
    "co2_data[\"date\"] = pd.to_datetime(co2_data[[\"year\", \"month\", \"day\"]])\n",
    "co2_data = co2_data[[\"date\", \"co2\"]]\n",
    "co2_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebbfa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(co2_data[\"date\"], co2_data[\"co2\"])\n",
    "plt.xlabel(\"date\")\n",
    "plt.ylabel(\"CO$_2$ concentration (ppm)\")\n",
    "_ = plt.title(\"Raw air samples measurements from the Mauna Loa Observatory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193aef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X = (co2_data[\"date\"].dt.year + co2_data[\"date\"].dt.month / 12).to_numpy()\n",
    "y = co2_data[\"co2\"].to_numpy()\n",
    "y = y.reshape(-1, 1)\n",
    "X = X.reshape(-1, 1)\n",
    "y_mean = np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gp_predictions(gaussian_process, kernel_name):\n",
    "    today = datetime.datetime.now()\n",
    "    current_month = today.year + today.month / 12\n",
    "    X_test = np.linspace(start=1958, stop=current_month,\n",
    "                         num=1_000).reshape(-1, 1)\n",
    "    mean_y_pred, std_y_pred = gaussian_process.predict(X_test, return_std=True)\n",
    "    mean_y_pred += y_mean\n",
    "\n",
    "    plt.plot(X, y, color=\"black\", linestyle=\"dashed\", label=\"Measurements\")\n",
    "    plt.plot(X_test, mean_y_pred, color=\"tab:blue\",\n",
    "             alpha=0.4, label=f\"Gaussian process\")\n",
    "    plt.fill_between(\n",
    "        X_test.ravel(),\n",
    "        mean_y_pred - std_y_pred,\n",
    "        mean_y_pred + std_y_pred,\n",
    "        color=\"tab:blue\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    plt.ylim(310, 400)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Monthly average of CO$_2$ concentration (ppm)\")\n",
    "    _ = plt.title(\n",
    "        f\"{kernel_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d4c950",
   "metadata": {},
   "source": [
    "# Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4628002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, ConstantKernel\n",
    "\n",
    "linear_kernel = ConstantKernel(10.)* \\\n",
    "    DotProduct()\n",
    "\n",
    "y_mean = y.mean()\n",
    "gaussian_process = GaussianProcessRegressor(\n",
    "    kernel=linear_kernel,\n",
    "    normalize_y=False,\n",
    "    alpha=1e-5,\n",
    "    n_restarts_optimizer=5,\n",
    ")\n",
    "gaussian_process.fit(X, y - y_mean)\n",
    "\n",
    "plot_gp_predictions(\n",
    "    gaussian_process, kernel_name=str(gaussian_process.kernel_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed9c3e4",
   "metadata": {},
   "source": [
    "# RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b92690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel\n",
    "\n",
    "rbf_kernel = ConstantKernel(100) * \\\n",
    "    RBF(length_scale=50.0, length_scale_bounds=(1e1, 1e6))\n",
    "\n",
    "y_mean = y.mean()\n",
    "gaussian_process = GaussianProcessRegressor(\n",
    "    kernel=rbf_kernel,\n",
    "    normalize_y=False,\n",
    "    alpha=1e-5,\n",
    "    n_restarts_optimizer=5,\n",
    ")\n",
    "gaussian_process.fit(X, y - y_mean)\n",
    "\n",
    "plot_gp_predictions(\n",
    "    gaussian_process, kernel_name=str(gaussian_process.kernel_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dd3971",
   "metadata": {},
   "source": [
    "# Periodic Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36897fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import ExpSineSquared, ConstantKernel\n",
    "\n",
    "periodic_kernel = (\n",
    "    ConstantKernel(100.0)\n",
    "    * ExpSineSquared(length_scale=1.0,\n",
    "                     periodicity=3.0,\n",
    "                     length_scale_bounds=(0.1, 100.0),\n",
    "                     periodicity_bounds=(1.0, 100.0),)\n",
    ")\n",
    "\n",
    "y_mean = y.mean()\n",
    "gaussian_process = GaussianProcessRegressor(\n",
    "    kernel=periodic_kernel,\n",
    "    normalize_y=False,\n",
    "    alpha=1e-4,\n",
    "    n_restarts_optimizer=5,\n",
    ")\n",
    "gaussian_process.fit(X, y - y_mean)\n",
    "\n",
    "plot_gp_predictions(\n",
    "    gaussian_process, kernel_name=str(gaussian_process.kernel_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd997be",
   "metadata": {},
   "source": [
    "# RBF + Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e43ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import RBF, DotProduct, ConstantKernel\n",
    "\n",
    "kernel = ConstantKernel(50.0**2) * RBF(length_scale=10.0, length_scale_bounds=(0.1, 100.0)) + \\\n",
    "    ConstantKernel(50.0**2) * DotProduct()\n",
    "\n",
    "y_mean = y.mean()\n",
    "gaussian_process = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    normalize_y=False,\n",
    "    alpha=1e-3,\n",
    "    n_restarts_optimizer=5,\n",
    ")\n",
    "gaussian_process.fit(X, y - y_mean)\n",
    "\n",
    "plot_gp_predictions(\n",
    "    gaussian_process, kernel_name=str(gaussian_process.kernel_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3494e54",
   "metadata": {},
   "source": [
    "# Custom kernel example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebefb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import RationalQuadratic, WhiteKernel\n",
    "long_term_trend_kernel = 50.0**2 * RBF(length_scale=50.0)\n",
    "seasonal_kernel = (\n",
    "    2.0**2\n",
    "    * RBF(length_scale=100.0)\n",
    "    * ExpSineSquared(length_scale=1.0, periodicity=1.0, periodicity_bounds=\"fixed\")\n",
    ")\n",
    "irregularities_kernel = 0.5**2 * RationalQuadratic(length_scale=1.0, alpha=1.0)\n",
    "\n",
    "noise_kernel = 0.1**2 * RBF(length_scale=0.1) + WhiteKernel(\n",
    "    noise_level=0.1**2, noise_level_bounds=(1e-5, 1e5)\n",
    ")\n",
    "co2_kernel = (\n",
    "    long_term_trend_kernel + seasonal_kernel + irregularities_kernel + noise_kernel\n",
    ")\n",
    "\n",
    "y_mean = y.mean()\n",
    "gaussian_process = GaussianProcessRegressor(\n",
    "    kernel=co2_kernel, normalize_y=False)\n",
    "gaussian_process.fit(X, y - y_mean)\n",
    "\n",
    "plot_gp_predictions(\n",
    "    gaussian_process, kernel_name=str(gaussian_process.kernel_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498c019a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4chem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
